{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"PaddleSeg generic example\"\n",
    "description: \"In this tutorial you can change the model choice between: OCRNet, SegFormer and PPLiteSeg.\"\n",
    "author: \"Allan Cerentini\"\n",
    "date: \"September 20, 2022\"\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.sandbox.google.com/github/lapix-ufsc/dl-tutorials/blob/main/tutorials/Semantic%20Segmentation/PaddleSeg/PaddleSeg_Lapix.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #Run this cell only once per notebook instance.\n",
    "\n",
    "# @markdown This cell is responsible for installing the Paddle base framework\n",
    "# and the segmentation version called PaddleSeg. After the installation is\n",
    "# complete a test script will run, it will download a small dataset and run\n",
    "# a neural network for a few iterations to verify that everything was installed\n",
    "# successfully.\n",
    "\n",
    "# @markdown You can check the box below to download and extract the cloud\n",
    "# dataset. This dataset contains 1223 images that contain the following 6\n",
    "# classes: Sky, Tree, Stratocumuliform, Stratiform, Cirriform and Cumuliform.\n",
    "# This dataset is already in the expected format, split into training and\n",
    "# validation, and can be used as a reference to adapt your dataset to the\n",
    "# expected format for PaddleSeg. At the end of the notebook we have a simple\n",
    "# script to convert a dataset to PaddleSeg's format.\n",
    "\n",
    "# @markdown ----\n",
    "download_cloud_dataset = True  # @param {type:\"boolean\"}\n",
    "\n",
    "# @markdown ----\n",
    "\n",
    "# @markdown ![](https://drive.google.com/uc?export=view&id=1SRt2rdFuKatHHQDSDLHt23ozbsEsRO0l) # noqa: E501\n",
    "\n",
    "!pip install paddlepaddle-gpu\n",
    "import paddle\n",
    "from google.colab import drive\n",
    "\n",
    "paddle.utils.run_check()\n",
    "\n",
    "\n",
    "print(paddle.__version__)\n",
    "\n",
    "!git clone https://github.com/PaddlePaddle/PaddleSeg\n",
    "%cd PaddleSeg\n",
    "!pip install -r requirements.txt\n",
    "!sh tests/run_check_install.sh\n",
    "!python setup.py install\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "%cd '/content/'\n",
    "\n",
    "\n",
    "if download_cloud_dataset:\n",
    "    !gdown 1nuk9mBOAQgaPF9WxnoKDBtGXFh3cUeEH\n",
    "    !unzip '/content/PaddleSegNuvens-ComArvore-1223.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opções Gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #Dataset settings.\n",
    "# @markdown Enter a file path:\n",
    "dataset_root = \"/content/PaddleSegNuvens-ComArvore-1223\"  # @param {type:\"string\"}\n",
    "folder_name_dataset = dataset_root.split(\"/\")[-1]\n",
    "train_path = (\n",
    "    \"/content/PaddleSegNuvens-ComArvore-1223/train-paddle.txt\"  # @param {type:\"string\"}\n",
    ")\n",
    "val_path = (\n",
    "    \"/content/PaddleSegNuvens-ComArvore-1223/val-paddle.txt\"  # @param {type:\"string\"}\n",
    ")\n",
    "num_classes = 6  # @param {type:\"number\"}\n",
    "\n",
    "# @markdown #Mean and standard deviation of the dataset, where r = red,\n",
    "# g = green and b = blue.\n",
    "mean_r = 0.37555224  # @param {type:\"number\"}\n",
    "mean_g = 0.47573688  # @param {type:\"number\"}\n",
    "mean_b = 0.51197395  # @param {type:\"number\"}\n",
    "\n",
    "std_r = 0.37555224  # @param {type:\"number\"}\n",
    "std_g = 0.47573688  # @param {type:\"number\"}\n",
    "std_b = 0.51197395  # @param {type:\"number\"}\n",
    "\n",
    "\n",
    "# @markdown #Train settings.\n",
    "batch_size = 4  # @param {type:\"number\"}\n",
    "iters = 80000  # @param {type:\"number\"}\n",
    "\n",
    "\n",
    "# @markdown #Enter the desired size so that the image will be resized to this\n",
    "# value. Set the original size so that it does not resize.\n",
    "target_size_x = 512  # @param {type:\"number\"}\n",
    "target_size_y = 512  # @param {type:\"number\"}\n",
    "\n",
    "size_folder_name = f\"{target_size_x}-{target_size_y}\"\n",
    "\n",
    "# @markdown #Transforms. These values add up to both the up and down\n",
    "# transformation. So 10 saturation will take the original value and can add or\n",
    "# remove up to 10 saturation units.\n",
    "\n",
    "saturation_range = 0.5  # @param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "contrast_range = 0.20  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "brightness_range = 0.20  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "\n",
    "base = f\"\"\"\n",
    "batch_size: {batch_size}\n",
    "iters: {iters}\n",
    "train_dataset:\n",
    "  type: Dataset\n",
    "  dataset_root: {dataset_root}\n",
    "  train_path: {train_path}\n",
    "  num_classes: {num_classes}\n",
    "  transforms:\n",
    "    - type: Resize\n",
    "      target_size: [{target_size_x}, {target_size_y}]\n",
    "    - type: RandomHorizontalFlip\n",
    "    - type: RandomVerticalFlip\n",
    "    - type: RandomDistort\n",
    "      brightness_range: {brightness_range}\n",
    "      contrast_range: {contrast_range}\n",
    "      saturation_range: {saturation_range}\n",
    "    - type: Normalize\n",
    "      mean: [{mean_r}, {mean_g}, {mean_b}]\n",
    "      std: [{std_r}, {std_g}, {std_b}]\n",
    "  mode: train\n",
    "\n",
    "val_dataset:\n",
    "  type: Dataset\n",
    "  dataset_root: {dataset_root}\n",
    "  val_path: {val_path}\n",
    "  num_classes: {num_classes}\n",
    "  transforms:\n",
    "    - type: Resize\n",
    "      target_size: [{target_size_x}, {target_size_y}]\n",
    "    - type: Normalize\n",
    "      mean: [{mean_r}, {mean_g}, {mean_b}]\n",
    "      std: [{std_r}, {std_g}, {std_b}]\n",
    "  mode: val\n",
    "\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models \n",
    "Run only one of the cells in this section. If you want to change the experiment, modify and run the cell again, or choose another cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #HRNet\n",
    "# @markdown ---\n",
    "# @markdown #Network Size\n",
    "HrNetSize = \"48\"  # @param [\"18\", \"48\"]\n",
    "# @markdown ---\n",
    "\n",
    "# @markdown #Paper: https://arxiv.org/abs/1909.11065\n",
    "# @markdown #Github: https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.6/configs/ocrnet # noqa: E501\n",
    "# @markdown #Overview  We propose a high-resolution network (HRNet). The HRNet\n",
    "# maintains high-resolution representations by connecting high-to-low\n",
    "# resolution convolutions in parallel and strengthens high-resolution\n",
    "# representations by repeatedly performing multi-scale fusions across\n",
    "# parallel convolutions. We demonstrate the effectives on pixel-level\n",
    "# classification, region-level classification, and image-level classification.\n",
    "\n",
    "\n",
    "# @markdown # noqa: E501 ![](https://jingdongwang2017.github.io/Projects/HRNet/images/HRNet.jpg)\n",
    "\n",
    "model_folder_name = f\"HrNet-{HrNetSize}\"\n",
    "logits_size = 2\n",
    "model = f\"\"\"\n",
    "\n",
    "model:\n",
    "  type: OCRNet\n",
    "  backbone:\n",
    "    type: HRNet_W{HrNetSize}\n",
    "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/hrnet_w{HrNetSize}_ssld.tar.gz\n",
    "  backbone_indices: [0]\n",
    "\"\"\"  # noqa: E501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SegFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #SegFormer\n",
    "\n",
    "# @markdown ---\n",
    "# @markdown #Network size.\n",
    "model_depth = \"B3\"  # @param [\"B1\", \"B2\", \"B3\", \"B4\", \"B5\"]\n",
    "# @markdown ---\n",
    "\n",
    "# @markdown #PPLiteSeg\n",
    "\n",
    "# @markdown #Paper: https://arxiv.org/abs/2105.15203\n",
    "# @markdown #Github: https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.6/configs/segformer # noqa: E501\n",
    "\n",
    "\n",
    "# @markdown #Overview:\n",
    "# @markdown SegFormer is a Transformer-based framework for semantic\n",
    "# segmentation that unifies Transformers with lightweight multilayer\n",
    "# perceptron (MLP) decoders. SegFormer has two appealing features:\n",
    "# 1) SegFormer comprises a novel hierarchically structured Transformer\n",
    "# encoder which outputs multiscale features. It does not need positional\n",
    "# encoding, thereby avoiding the interpolation of positional codes which leads\n",
    "# to decreased performance when the testing resolution differs from training.\n",
    "# 2) SegFormer avoids complex decoders. The proposed MLP decoder aggregates\n",
    "# information from different layers, and thus combining both local attention\n",
    "# and global attention to render powerful representations.\n",
    "\n",
    "# @markdown ![](https://production-media.paperswithcode.com/methods/c84b18b5-4329-49fc-a5f2-804ef580a966.png) # noqa: E501\n",
    "model_depth_down = model_depth.lower()\n",
    "\n",
    "model_folder_name = f\"SegFormer-{model_depth}\"\n",
    "logits_size = 2\n",
    "model = f\"\"\"\n",
    "\n",
    "model:\n",
    "  type: SegFormer_{model_depth}\n",
    "  num_classes: {num_classes}\n",
    "  pretrained: https://bj.bcebos.com/paddleseg/dygraph/mix_vision_transformer_{model_depth_down}.tar.gz\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPLiteSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #PPLiteSeg\n",
    "\n",
    "# @markdown ---\n",
    "# @markdown #Network size.\n",
    "STDC = 2  # @param {type:\"slider\", min:1, max:2, step:1}\n",
    "# @markdown ---\n",
    "\n",
    "# @markdown #Paper: https://arxiv.org/abs/2204.02681\n",
    "# @markdown #Github: https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.6/configs/pp_liteseg # noqa: E501\n",
    "\n",
    "# @markdown #Overview:\n",
    "\n",
    "# @markdown Overview: We propose PP-LiteSeg, a novel lightweight model for the\n",
    "# real-time semantic segmentation task. Specifically, we present a Flexible and\n",
    "# Lightweight Decoder (FLD) to reduce computation overhead of previous decoder.\n",
    "# To strengthen feature representations, we propose a Unified Attention Fusion\n",
    "# Module (UAFM), which takes advantage of spatial and channel attention to\n",
    "# produce a weight and then fuses the input features with the weight. Moreover,\n",
    "# a Simple Pyramid Pooling Module (SPPM) is proposed to aggregate global\n",
    "# context with low computation cost.\n",
    "\n",
    "\n",
    "# @markdown ![](https://user-images.githubusercontent.com/52520497/162148786-c8b91fd1-d006-4bad-8599-556daf959a75.png) # noqa: E501\n",
    "\n",
    "\n",
    "model_folder_name = f\"PPLiteSeg-{STDC}\"\n",
    "logits_size = 3\n",
    "model = f\"\"\"\n",
    "\n",
    "model:\n",
    "  type: PPLiteSeg\n",
    "  backbone:\n",
    "    type: STDC{STDC}\n",
    "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/PP_STDCNet{STDC}.tar.gz\n",
    "  arm_out_chs: [32, 64, 128]\n",
    "  seg_head_inter_chs: [32, 64, 64]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer\n",
    "If you want to change the experiment, modify and run the cell again, or choose another cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #AdamW\n",
    "# @markdown #Paper: https://arxiv.org/pdf/1711.05101.pdf\n",
    "# @markdown #API: https://www.paddlepaddle.org.cn/documentation/docs/en/2.2/api/paddle/optimizer/AdamW_en.html#adamw # noqa: E501\n",
    "\n",
    "\n",
    "# @markdown #The exponential decay rate for the 1st moment estimates.\n",
    "beta1 = 0.4  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "# @markdown #The exponential decay rate for the 2nd moment estimates.\n",
    "beta2 = 0.984  # @param {type:\"slider\", min:0, max:1, step:0.001}\n",
    "# @markdown #The weight decay coefficient.\n",
    "weight_decay = 0.001  # @param {type:\"number\"}\n",
    "\n",
    "optimizer = f\"\"\"\n",
    "optimizer:\n",
    "  type: AdamW\n",
    "  beta1: {beta1}\n",
    "  beta2: {beta2}\n",
    "  weight_decay: {weight_decay}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #SGD\n",
    "# @markdown #API: https://www.paddlepaddle.org.cn/documentation/docs/en/2.2/api/paddle/optimizer/SGD_en.html#sgd # noqa: E501\n",
    "\n",
    "momentum = 0.9  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "weight_decay = 0.0005  # @param {type:\"number\"}\n",
    "\n",
    "optimizer = f\"\"\"\n",
    "optimizer:\n",
    "  type: sgd\n",
    "  momentum: {momentum}\n",
    "  weight_decay: {weight_decay}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate\n",
    "If you want to change the experiment, modify and run the cell again, or choose another cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PolynomialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #PolynomialDecay\n",
    "\n",
    "learning_rate = 0.9  # @param {type:\"number\"}\n",
    "weight_decay = 0.0005  # @param {type:\"number\"}\n",
    "warmup_iters = 1000  # @param {type:\"number\"}\n",
    "warmup_start_lr_power = 5  # @param {type:\"slider\", min:0, max:6, step:1}\n",
    "\n",
    "\n",
    "lr_scheduler = f\"\"\"\n",
    "\n",
    "lr_scheduler:\n",
    "  type: PolynomialDecay\n",
    "  learning_rate: {learning_rate}\n",
    "  end_lr: 0\n",
    "  power: 0.9\n",
    "  warmup_iters: {warmup_iters}\n",
    "  warmup_start_lr: 1.0e-{warmup_start_lr_power}\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    "If you want to change the experiment, modify and run the cell again, or choose another cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #CrossEntropyLoss\n",
    "# @markdown #Api: https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.6/paddleseg/models/losses/cross_entropy_loss.py # noqa: E501\n",
    "\n",
    "# weight_list = '0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.2' #@param {type:\"string\"}\n",
    "\n",
    "folder_name_loss = \"CrossEntropyLoss\"\n",
    "\n",
    "loss = f\"\"\"\n",
    "\n",
    "loss:\n",
    "  types:\n",
    "    - type: MixedLoss\n",
    "      losses:\n",
    "        - type: CrossEntropyLoss\n",
    "      coef: [1]\n",
    "  coef: {[1 for i in list(range(logits_size))]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DetailAggregateLoss (Single Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #DetailAggregateLoss (Single Class)\n",
    "\n",
    "# @markdown #Paper: https://arxiv.org/abs/2104.13188\n",
    "# @markdown #API: https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.6/paddleseg/models/losses/detail_aggregate_loss.py # noqa: E501\n",
    "\n",
    "\n",
    "folder_name_loss = \"DetailAggregateLoss\"\n",
    "cross_entropy_weight = 0.2  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "detail_aggregated_weight = 0.2  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "\n",
    "loss = f\"\"\"\n",
    "\n",
    "loss:\n",
    "  types:\n",
    "    - type: MixedLoss\n",
    "      losses:\n",
    "        - type: CrossEntropyLoss\n",
    "        - type: DetailAggregateLoss\n",
    "      coef: [{cross_entropy_weight}, {detail_aggregated_weight}]\n",
    "  coef: {[1 for i in list(range(logits_size))]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EdgeAttentionLoss (Single Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #EdgeAttentionLoss (Single Class)\n",
    "\n",
    "# @markdown #Implements the cross entropy loss function. It only compute the edge part.\n",
    "# @markdown #API: https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.6/paddleseg/models/losses/edge_attention_loss.py\n",
    "\n",
    "folder_name_loss = \"EdgeAttentionLoss\"\n",
    "\n",
    "cross_entropy_weight = 0.8  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "edge_attention_weight = 0.2  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "\n",
    "loss = f\"\"\"\n",
    "\n",
    "loss:\n",
    "  types:\n",
    "    - type: MixedLoss\n",
    "      losses:\n",
    "        - type: CrossEntropyLoss\n",
    "        - type: EdgeAttentionLoss\n",
    "      coef: [{cross_entropy_weight}, {edge_attention_weight}]\n",
    "  coef: {[1 for i in list(range(logits_size))]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PixelContrastCrossEntropyLoss (Arrumar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #PixelContrastCrossEntropyLoss (Arrumar)\n",
    "\n",
    "# @markdown #Paper: https://arxiv.org/abs/2101.11939\n",
    "\n",
    "# @markdown #API: https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.6/paddleseg/models/losses/pixel_contrast_cross_entropy_loss.py # noqa: E501\n",
    "\n",
    "folder_name_loss = \"PixelContrastCrossEntropyLoss\"\n",
    "\n",
    "temperature = 0.1  # @param {type:\"number\"}\n",
    "base_temperature = 0.07  # @param {type:\"number\"}\n",
    "max_samples = 1024  # @param {type:\"number\"}\n",
    "max_views = 100  # @param {type:\"number\"}\n",
    "\n",
    "cross_entropy_weight = 0.8  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "pixel_contrast_weight = 0.2  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "\n",
    "\n",
    "loss = f\"\"\"\n",
    "\n",
    "loss:\n",
    "  types:\n",
    "    - type: MixedLoss\n",
    "      losses:\n",
    "        - type: CrossEntropyLoss\n",
    "        - type: PixelContrastCrossEntropyLoss\n",
    "          temperature: {temperature}\n",
    "          base_temperature: {base_temperature}\n",
    "          ignore_index: 255\n",
    "          max_samples: {max_samples}\n",
    "          max_views: {max_views}\n",
    "       coef: [{cross_entropy_weight}, {pixel_contrast_weight}]\n",
    "  coef: {[1 for i in list(range(logits_size))]}\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SemanticConnectivityLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown #SemanticConnectivityLoss\n",
    "\n",
    "# @markdown #Paper: https://arxiv.org/abs/2112.07146\n",
    "\n",
    "# @markdown #API: https://github.com/PaddlePaddle/PaddleSeg/blob/release/2.6/paddleseg/models/losses/semantic_connectivity_loss.py # noqa: E501\n",
    "\n",
    "folder_name_loss = \"SemanticConnectivityLoss\"\n",
    "\n",
    "\n",
    "# @markdown Maximum number of predicted connected components. At the beginning\n",
    "# of training, there will be a large number of connected components, and the\n",
    "# calculation is very time-consuming. Therefore, it is necessary to limit the\n",
    "# maximum number of predicted connected components, and the rest will not\n",
    "# participate in the calculation.\n",
    "\n",
    "\n",
    "max_pred_num_conn = 10  # @param {type:\"number\"}\n",
    "\n",
    "cross_entropy_weight = 0.8  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "semantic_connectivity_weight = 0.2  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "\n",
    "\n",
    "loss = f\"\"\"\n",
    "\n",
    "loss:\n",
    "  types:\n",
    "    - type: MixedLoss\n",
    "      losses:\n",
    "        - type: CrossEntropyLoss\n",
    "        - type: SemanticConnectivityLoss\n",
    "          max_pred_num_conn: {max_pred_num_conn}\n",
    "      coef: [{cross_entropy_weight}, {edge_attention_weight}]\n",
    "  coef: {[1 for i in list(range(logits_size))]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n",
    "#@title Run Experiment\n",
    "import os\n",
    "\n",
    "file_content = base + model + optimizer + loss + lr_scheduler \n",
    "\n",
    "\n",
    "experiment_name = os.path.join(folder_name_dataset, model_folder_name, folder_name_loss)\n",
    "resume_model = False\n",
    "save_interval = 200 #@param {type:\"number\"}\n",
    "save_dir_path = '/content/drive/Shareddrives/Nuvens/0Allan/PaddleSegTest' #@param {type:\"string\"}\n",
    "save_dir_exp = os.path.join(save_dir_path, experiment_name)\n",
    "config_file = os.path.join(save_dir_exp, 'config-file.yml')\n",
    "\n",
    "os.makedirs(save_dir_exp, exist_ok=True)\n",
    "\n",
    "#@markdown Resume Experiment?\n",
    "resume_experiment = False #@param {type:\"boolean\"}\n",
    "checkpoint_path = \"/content/drive/Shareddrives/Nuvens/resultados_allan/allan/paddleseg/hrnet18-ocr-comarvore-halfres/iter_9500\" #@param {type:\"string\"}\n",
    "resume_config_file = '/content/drive/Shareddrives/Nuvens/0Allan/PaddleSegTest/PaddleSegNuvens-ComArvore-1223/HrNet-48/DetailAggregateLoss/config-file.yml' #@param {type:\"string\"}\n",
    "\n",
    "with open(config_file, \"w\") as text_file:\n",
    "  text_file.write(file_content)\n",
    "\n",
    "\n",
    "print(config_file)\n",
    "\n",
    "!python /content/PaddleSeg/train.py \\\n",
    "    --config $config_file \\\n",
    "    --do_eval \\\n",
    "    --use_vdl \\\n",
    "    --save_interval $save_interval \\\n",
    "    --save_dir $save_dir_exp\n",
    "\n",
    "if resume_experiment:\n",
    "    print(f'Resuming from {save_dir_exp}')\n",
    "    !python /content/PaddleSeg/train.py \\\n",
    "        --config $resume_config_file \\\n",
    "        --do_eval \\\n",
    "        --use_vdl \\\n",
    "        --save_interval $save_interval \\\n",
    "        --save_dir $save_dir_exp \\\n",
    "        --resume_model $checkpoint_path       \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Predict Folder with trained model\n",
    "\n",
    "\n",
    "#@markdown Files created in the training Experiment\n",
    "checkpoint_path = \"/content/drive/Shareddrives/Nuvens/resultados_allan/allan/paddleseg/hrnet18-ocr-comarvore-halfres/iter_9500\" #@param {type:\"string\"}\n",
    "config_file = '/content/drive/Shareddrives/Nuvens/0Allan/PaddleSegTest/PaddleSegNuvens-ComArvore-1223/HrNet-48/DetailAggregateLoss/config-file.yml' #@param {type:\"string\"}\n",
    "model_params = '/content/drive/Shareddrives/Nuvens/resultados_allan/allan/paddleseg/hrnet18-ocr-comarvore-halfres/best_model/model.pdparams' #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Folder to predict\n",
    "image_folder = '/content/drive/MyDrive/Datasets/2022-05-13' #@param {type:\"string\"}\n",
    "#@markdown Folder to save the predictions\n",
    "dest_folder = '/content/drive/Shareddrives/Nuvens/resultados_allan/allan/paddleseg/hrnet18-ocr-comarvore-halfres/cam1-2022-05-13' #@param {type:\"string\"}\n",
    "#@markdown Custom color pallet, the format is a sequential RGB value for each class, and all values are separated by a space. \n",
    "#@markdown In the example bellow, 0 0 0 is the value for the class zero, 7 25 163 is the value for the class one and so and on.\n",
    "color_pallet = '0 0 0 7 25 163 20 85 189 32 145 215 45 205 241 42 255 49' #@param {type:\"string\"}\n",
    "\n",
    "!python /content/PaddleSeg/predict.py \\\n",
    "       --config $config_file \\\n",
    "       --model_path  \\\n",
    "       --image_path $image_folder \\\n",
    "       --save_dir  $dest_folder \\\n",
    "       --custom_color $color_pallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title String fields\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "mask_ext = \"png\"  # @param {type:\"string\"}\n",
    "image_ext = \"jpg\"  # @param {type:\"string\"}\n",
    "dataset_root = \"/content/PaddleSegNuvens-ComArvore-1223/\"  # @param {type:\"string\"}\n",
    "\n",
    "masks = glob.glob(\n",
    "    os.path.join(Path(dataset_root), \"**\", f\"*.{mask_ext}\"), recursive=True\n",
    ")\n",
    "mask_image_tuple_list = []\n",
    "\n",
    "print(f\"Number of masks found: {len(masks)}\")\n",
    "for mask in tqdm(masks):\n",
    "    file_name = Path(mask).stem\n",
    "    image = glob.glob(\n",
    "        os.path.join(Path(dataset_root), \"**\", f\"{file_name}.{image_ext}\"),\n",
    "        recursive=True,\n",
    "    )[0]\n",
    "    mask_relative = mask.replace(dataset_root, \"\")\n",
    "    image_relative = image.replace(dataset_root, \"\")\n",
    "\n",
    "    mask_image_tuple_list.append((image_relative, mask_relative))\n",
    "\n",
    "validation_percentage = 0.25  # @param {type:\"slider\", min:0.1, max:0.9, step:0.05}\n",
    "\n",
    "X_train, X_test = train_test_split(mask_image_tuple_list, test_size=0.2)\n",
    "\n",
    "train_file = os.path.join(dataset_root, \"train-paddle2.txt\")\n",
    "val_file = os.path.join(dataset_root, \"val-paddle2.txt\")\n",
    "\n",
    "with open(train_file, \"w\") as file:\n",
    "    print(f\"Train Size: {len(X_train)}\")\n",
    "    for line in tqdm(X_train):\n",
    "        file.write(f\"{line[0]} {line[1]}\\n\")\n",
    "\n",
    "with open(val_file, \"w\") as file:\n",
    "    print(f\"Validation Size: {len(X_test)}\")\n",
    "    for line in tqdm(X_test):\n",
    "        file.write(f\"{line[0]} {line[1]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
